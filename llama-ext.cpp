/////////////////////////////////////////////////////////////////////////////////////
// This file will be concatenated to llama.cpp in order to access all internal APIs
/////////////////////////////////////////////////////////////////////////////////////

